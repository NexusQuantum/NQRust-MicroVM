name: Release

on:
  push:
    tags:
      - 'v*.*.*'
  workflow_dispatch:
    inputs:
      version:
        description: 'Version to release (e.g., v1.0.0)'
        required: true
        type: string

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1
  # Optimize build performance
  RUSTFLAGS: "-C link-arg=-fuse-ld=lld"

jobs:
  # Gate: Ensure CI passes before building release
  ci-gate:
    name: CI Gate
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy

      - name: Check formatting
        run: cargo fmt -- --check

      - name: Run clippy
        run: cargo clippy --all-targets --all-features -- -D warnings

      - name: Install cargo-audit
        run: cargo install cargo-audit

      - name: Run security audit
        run: cargo audit

      - name: Check shell scripts
        run: |
          sudo apt-get update && sudo apt-get install -y shellcheck
          find scripts/install -name "*.sh" -type f -exec bash -n {} \;
          find scripts/install -name "*.sh" -type f -exec shellcheck -x {} \;

  build-binaries:
    name: Build Release Binaries
    needs: ci-gate
    runs-on: self-hosted
    # Alternatives:
    # runs-on: ubuntu-24.04
    # runs-on: buildjet-4vcpu-ubuntu-2204
    strategy:
      matrix:
        target:
          - x86_64-unknown-linux-gnu

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          targets: x86_64-unknown-linux-gnu,x86_64-unknown-linux-musl

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            build-essential \
            pkg-config \
            libssl-dev \
            musl-tools \
            lld \
            clang \
            postgresql \
            postgresql-contrib

      - name: Setup PostgreSQL
        run: |
          # Start PostgreSQL if not running
          sudo systemctl start postgresql || true

          # Create database and user if they don't exist
          sudo -u postgres psql -tc "SELECT 1 FROM pg_database WHERE datname = 'nexus'" | grep -q 1 || \
            sudo -u postgres psql -c "CREATE DATABASE nexus;"

          sudo -u postgres psql -tc "SELECT 1 FROM pg_user WHERE usename = 'nexus'" | grep -q 1 || \
            sudo -u postgres psql -c "CREATE USER nexus WITH PASSWORD 'nexus';"

          sudo -u postgres psql -c "GRANT ALL PRIVILEGES ON DATABASE nexus TO nexus;" || true
          sudo -u postgres psql -d nexus -c "GRANT ALL ON SCHEMA public TO nexus;" || true

      - name: Setup sccache (local)
        run: |
          # Install sccache if not present
          if ! command -v sccache &> /dev/null; then
            curl -L https://github.com/mozilla/sccache/releases/download/v0.7.7/sccache-v0.7.7-x86_64-unknown-linux-musl.tar.gz | tar xz
            sudo mv sccache-*/sccache /usr/local/bin/
          fi
          # Use local disk cache
          echo "RUSTC_WRAPPER=sccache" >> $GITHUB_ENV
          echo "SCCACHE_DIR=$HOME/.cache/sccache" >> $GITHUB_ENV

      - name: Cache Cargo registry
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
          key: ${{ runner.os }}-cargo-registry-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-registry-

      - name: Build manager (release)
        run: cargo build --release -p manager
        env:
          DATABASE_URL: postgresql://nexus:nexus@localhost/nexus

      - name: Build agent (release)
        run: cargo build --release -p agent

      - name: Build guest-agent (static musl)
        run: cargo build --release --target x86_64-unknown-linux-musl -p guest-agent

      - name: Build installer (static musl)
        run: cargo build --release --target x86_64-unknown-linux-musl -p nqr-installer

      - name: Verify binaries
        run: |
          # Verify binaries exist and are executable (skip --version to avoid port conflicts)
          test -x ./target/release/manager
          file ./target/release/manager
          test -x ./target/release/agent
          file ./target/release/agent
          # Check guest-agent is statically linked (handles both "statically linked" and "static-pie linked")
          file target/x86_64-unknown-linux-musl/release/guest-agent | grep -E "static.*linked"
          # Check installer is statically linked
          test -x target/x86_64-unknown-linux-musl/release/nqr-installer
          file target/x86_64-unknown-linux-musl/release/nqr-installer | grep -E "static.*linked"

      - name: Rename binaries with target suffix
        run: |
          cp target/release/manager nqrust-manager-${{ matrix.target }}
          cp target/release/agent nqrust-agent-${{ matrix.target }}
          cp target/x86_64-unknown-linux-musl/release/guest-agent nqrust-guest-agent-x86_64-linux-musl
          cp target/x86_64-unknown-linux-musl/release/nqr-installer nqr-installer-x86_64-linux-musl

      - name: Upload binaries as artifacts
        uses: actions/upload-artifact@v4
        with:
          name: binaries-${{ matrix.target }}
          path: |
            nqrust-manager-${{ matrix.target }}
            nqrust-agent-${{ matrix.target }}
            nqrust-guest-agent-x86_64-linux-musl
            nqr-installer-x86_64-linux-musl
          retention-days: 1

      - name: Show sccache statistics
        run: sccache --show-stats

  build-images:
    name: Build Base Images
    needs: [ci-gate, build-binaries]
    runs-on: self-hosted
    # This job builds VM images (kernels, rootfs, runtimes)
    # Requires: KVM access, ~10GB disk space, internet for downloads
    # Now depends on build-binaries so guest-agent binary is available

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Clean up and check disk space
        run: |
          # Clean up from any previous runs - INCLUDING alpine cache to ensure fresh builds
          sudo rm -rf /tmp/ubuntu-rootfs /tmp/node-rootfs /tmp/python-rootfs /tmp/alpine-*.tar.gz 2>/dev/null || true
          sudo rm -rf /mnt/alpine /mnt/busybox /mnt/ubuntu /mnt/node /mnt/python /mnt/container 2>/dev/null || true
          sudo rm -rf /tmp/alpine-cache 2>/dev/null || true
          # Clean up any old build directories from runtime scripts
          sudo rm -rf /tmp/build-node-runtime /tmp/build-python-runtime /tmp/build-bun-runtime 2>/dev/null || true
          sudo rm -rf "$(pwd)/build-node-runtime" "$(pwd)/build-python-runtime" "$(pwd)/build-bun-runtime" 2>/dev/null || true
          # IMPORTANT: Remove any cached runtime images from previous builds on self-hosted runner
          sudo rm -f /srv/images/node-runtime.ext4 /srv/images/python-runtime.ext4 /srv/images/bun-runtime.ext4 2>/dev/null || true
          # Show available disk space
          echo "=== Disk space ==="
          df -h /tmp
          df -h .

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            qemu-utils \
            debootstrap \
            e2fsprogs \
            curl \
            xz-utils \
            cpio \
            bc \
            flex \
            bison \
            libelf-dev \
            libssl-dev

      - name: Create images directory
        run: |
          # Remove any existing images to force fresh builds
          rm -rf images/
          mkdir -p images/

      - name: Download guest-agent from build-binaries
        uses: actions/download-artifact@v4
        with:
          name: binaries-x86_64-unknown-linux-gnu
          path: /tmp/binaries/

      - name: Setup guest-agent for image builds
        run: |
          # Copy guest-agent to expected location for build scripts
          mkdir -p target/x86_64-unknown-linux-musl/release/
          cp /tmp/binaries/nqrust-guest-agent-x86_64-linux-musl target/x86_64-unknown-linux-musl/release/guest-agent
          chmod +x target/x86_64-unknown-linux-musl/release/guest-agent
          echo "Guest-agent ready for image builds:"
          ls -la target/x86_64-unknown-linux-musl/release/guest-agent

      - name: Download Firecracker kernel
        run: |
          # Download pre-built Firecracker kernel 5.10
          curl -fsSL -o images/vmlinux-5.10.fc.bin \
            https://s3.amazonaws.com/spec.ccfc.min/img/quickstart_guide/x86_64/kernels/vmlinux.bin
          ls -lh images/vmlinux-5.10.fc.bin

      - name: Build Alpine rootfs
        run: |
          # Use pre-built Alpine mini root filesystem
          ALPINE_VERSION=3.18
          curl -fsSL -o /tmp/alpine-minirootfs.tar.gz \
            https://dl-cdn.alpinelinux.org/alpine/v${ALPINE_VERSION}/releases/x86_64/alpine-minirootfs-${ALPINE_VERSION}.0-x86_64.tar.gz

          # Create ext4 image (50MB for Alpine minirootfs - it's about 8MB compressed but needs space for extraction)
          dd if=/dev/zero of=images/alpine-3.18-minimal.ext4 bs=1M count=50
          mkfs.ext4 -F images/alpine-3.18-minimal.ext4

          # Mount and populate
          sudo mkdir -p /mnt/alpine
          sudo mount -o loop images/alpine-3.18-minimal.ext4 /mnt/alpine
          sudo tar -xzf /tmp/alpine-minirootfs.tar.gz -C /mnt/alpine

          # Basic setup - create required directories
          sudo mkdir -p /mnt/alpine/etc/init.d /mnt/alpine/sbin
          sudo sh -c 'echo "nameserver 8.8.8.8" > /mnt/alpine/etc/resolv.conf'
          
          # Ensure /sbin/init exists (kernel boot arg uses init=/sbin/init)
          # Alpine minirootfs has busybox but might not have init symlink
          sudo ln -sf /bin/busybox /mnt/alpine/sbin/init 2>/dev/null || true
          sudo ln -sf /bin/busybox /mnt/alpine/sbin/getty 2>/dev/null || true
          sudo ln -sf /bin/busybox /mnt/alpine/sbin/ifconfig 2>/dev/null || true
          sudo ln -sf /bin/busybox /mnt/alpine/sbin/udhcpc 2>/dev/null || true
          sudo ln -sf /bin/busybox /mnt/alpine/sbin/route 2>/dev/null || true
          sudo ln -sf /bin/busybox /mnt/alpine/sbin/reboot 2>/dev/null || true
          
          # Create passwd and shadow if they don't exist (Alpine minirootfs should have them)
          sudo sh -c 'test -f /mnt/alpine/etc/passwd || echo "root:x:0:0:root:/root:/bin/sh" > /mnt/alpine/etc/passwd'
          sudo sh -c 'test -f /mnt/alpine/etc/shadow || echo "root::0:0:99999:7:::" > /mnt/alpine/etc/shadow'
          sudo sh -c 'test -f /mnt/alpine/etc/group || echo "root:x:0:" > /mnt/alpine/etc/group'
          
          # Set root password using chpasswd or fallback to direct shadow edit
          sudo chroot /mnt/alpine sh -c 'echo "root:root" | chpasswd' 2>/dev/null || \
            sudo sed -i 's|^root:[^:]*:|root:$6$rounds=4096$saltsalt$YW5vbnltb3VzcGFzc3dvcmQ=:|' /mnt/alpine/etc/shadow || true
          
          # Create empty rc.local that guest-agent installer can append to
          printf '%s\n' '#!/bin/sh' '# rc.local - executed at boot' 'exit 0' | sudo tee /mnt/alpine/etc/rc.local > /dev/null
          sudo chmod +x /mnt/alpine/etc/rc.local

          # Create inittab for BusyBox init (includes rc.local execution)
          printf '%s\n' \
            '::sysinit:/bin/mount -t proc proc /proc' \
            '::sysinit:/bin/mount -t sysfs sysfs /sys' \
            '::sysinit:/bin/mount -o remount,rw /' \
            '::sysinit:/bin/mkdir -p /dev/pts /dev/shm' \
            '::sysinit:/bin/mount -t devpts devpts /dev/pts' \
            '::sysinit:/sbin/ifconfig lo 127.0.0.1 up' \
            '::sysinit:/sbin/udhcpc -i eth0 -s /usr/share/udhcpc/default.script -q -b 2>/dev/null &' \
            '::sysinit:/bin/hostname alpine-vm' \
            '::sysinit:/bin/sh /etc/rc.local' \
            'ttyS0::respawn:/sbin/getty -L -n -l /bin/sh ttyS0 115200 vt100' \
            '::ctrlaltdel:/sbin/reboot' \
            '::shutdown:/bin/umount -a -r' \
            | sudo tee /mnt/alpine/etc/inittab > /dev/null

          # Create udhcpc script for DHCP
          sudo mkdir -p /mnt/alpine/usr/share/udhcpc
          printf '%s\n' \
            '#!/bin/sh' \
            'case "$1" in' \
            '    bound|renew)' \
            '        [ -n "$ip" ] && ifconfig $interface $ip netmask ${subnet:-255.255.255.0}' \
            '        [ -n "$router" ] && route add default gw $router' \
            '        [ -n "$dns" ] && echo "nameserver $dns" > /etc/resolv.conf' \
            '        ;;' \
            'esac' \
            | sudo tee /mnt/alpine/usr/share/udhcpc/default.script > /dev/null
          sudo chmod +x /mnt/alpine/usr/share/udhcpc/default.script

          # Set default TERM for serial console
          sudo mkdir -p /mnt/alpine/etc/profile.d
          echo 'export TERM=vt100' | sudo tee /mnt/alpine/etc/profile.d/term.sh
          sudo chmod +x /mnt/alpine/etc/profile.d/term.sh

          sudo umount /mnt/alpine
          ls -lh images/alpine-3.18-minimal.ext4

      - name: Build BusyBox rootfs
        run: |
          # Create minimal BusyBox rootfs
          # Using 1.35.0 - latest available pre-built binary from busybox.net
          curl -fsSL -o /tmp/busybox \
            https://busybox.net/downloads/binaries/1.35.0-x86_64-linux-musl/busybox

          # Create ext4 image (80MB for BusyBox with basic utilities)
          dd if=/dev/zero of=images/busybox-1.35.ext4 bs=1M count=80
          mkfs.ext4 -F images/busybox-1.35.ext4

          # Mount and populate
          sudo mkdir -p /mnt/busybox
          sudo mount -o loop images/busybox-1.35.ext4 /mnt/busybox

          # Create directory structure (including init.d for init system detection)
          sudo mkdir -p /mnt/busybox/{bin,sbin,etc/init.d,proc,sys,usr/bin,usr/sbin,usr/local/bin,dev,tmp,root,var/run,etc/profile.d,usr/share/udhcpc}

          # Install BusyBox
          sudo cp /tmp/busybox /mnt/busybox/bin/busybox
          sudo chmod +x /mnt/busybox/bin/busybox
          sudo chroot /mnt/busybox /bin/busybox --install -s
          
          # Create passwd, shadow, group for credential injection
          echo 'root:x:0:0:root:/root:/bin/sh' | sudo tee /mnt/busybox/etc/passwd > /dev/null
          echo 'root::0:0:99999:7:::' | sudo tee /mnt/busybox/etc/shadow > /dev/null
          echo 'root:x:0:' | sudo tee /mnt/busybox/etc/group > /dev/null
          sudo chmod 640 /mnt/busybox/etc/shadow
          
          # Set root password (simple hash for 'root')
          sudo sed -i 's|^root:[^:]*:|root:$6$xyz$LnPPryZ4VPKRvJnuZCvJx9QKUX.j8EJn2nzJdRN8VYs2YgVqfkFpBKL7Gkzp3wDPYpKzXjYzLFPqwV7sM1sQK/:|' /mnt/busybox/etc/shadow
          
          # Create resolv.conf
          echo 'nameserver 8.8.8.8' | sudo tee /mnt/busybox/etc/resolv.conf > /dev/null
          
          # Create empty rc.local that guest-agent installer can append to
          printf '%s\n' '#!/bin/sh' '# rc.local - executed at boot' 'exit 0' | sudo tee /mnt/busybox/etc/rc.local > /dev/null
          sudo chmod +x /mnt/busybox/etc/rc.local

          # Create /etc/inittab for BusyBox init (includes rc.local execution)
          printf '%s\n' \
            '::sysinit:/bin/mount -t proc proc /proc' \
            '::sysinit:/bin/mount -t sysfs sysfs /sys' \
            '::sysinit:/bin/mount -o remount,rw /' \
            '::sysinit:/bin/mkdir -p /dev/pts /dev/shm' \
            '::sysinit:/bin/mount -t devpts devpts /dev/pts' \
            '::sysinit:/sbin/ifconfig lo 127.0.0.1 up' \
            '::sysinit:/sbin/udhcpc -i eth0 -s /usr/share/udhcpc/default.script -q -b 2>/dev/null &' \
            '::sysinit:/bin/hostname busybox-vm' \
            '::sysinit:/bin/sh /etc/rc.local' \
            'ttyS0::respawn:/sbin/getty -L -n -l /bin/sh ttyS0 115200 vt100' \
            '::ctrlaltdel:/sbin/reboot' \
            '::shutdown:/bin/umount -a -r' \
            | sudo tee /mnt/busybox/etc/inittab > /dev/null

          # Create udhcpc script for DHCP
          printf '%s\n' \
            '#!/bin/sh' \
            'case "$1" in' \
            '    bound|renew)' \
            '        [ -n "$ip" ] && ifconfig $interface $ip netmask ${subnet:-255.255.255.0}' \
            '        [ -n "$router" ] && route add default gw $router' \
            '        [ -n "$dns" ] && echo "nameserver $dns" > /etc/resolv.conf' \
            '        ;;' \
            'esac' \
            | sudo tee /mnt/busybox/usr/share/udhcpc/default.script > /dev/null
          sudo chmod +x /mnt/busybox/usr/share/udhcpc/default.script

          # Set default TERM for serial console
          echo 'export TERM=vt100' | sudo tee /mnt/busybox/etc/profile.d/term.sh
          sudo chmod +x /mnt/busybox/etc/profile.d/term.sh

          sudo umount /mnt/busybox
          ls -lh images/busybox-1.35.ext4

      - name: Build Ubuntu minimal rootfs
        run: |
          # Download official Ubuntu 24.04 cloud image (minimal rootfs)
          # Using cloud image instead of debootstrap - faster and more reliable
          UBUNTU_URL="https://cloud-images.ubuntu.com/minimal/releases/noble/release/ubuntu-24.04-minimal-cloudimg-amd64-root.tar.xz"

          echo "Downloading Ubuntu 24.04 minimal cloud image..."
          curl -fsSL -o /tmp/ubuntu-rootfs.tar.xz "$UBUNTU_URL"

          # Create ext4 image (800MB for Ubuntu minimal)
          dd if=/dev/zero of=images/ubuntu-24.04-minimal.ext4 bs=1M count=800
          mkfs.ext4 -F images/ubuntu-24.04-minimal.ext4

          # Mount and extract
          sudo mkdir -p /mnt/ubuntu
          sudo mount -o loop images/ubuntu-24.04-minimal.ext4 /mnt/ubuntu
          sudo tar -xJf /tmp/ubuntu-rootfs.tar.xz -C /mnt/ubuntu

          # Set root password
          sudo chroot /mnt/ubuntu sh -c 'echo "root:root" | chpasswd'

          # Enable serial console
          sudo chroot /mnt/ubuntu systemctl enable serial-getty@ttyS0.service || true

          # Set default TERM for serial console
          sudo mkdir -p /mnt/ubuntu/etc/profile.d
          echo 'export TERM=vt100' | sudo tee /mnt/ubuntu/etc/profile.d/term.sh
          sudo chmod +x /mnt/ubuntu/etc/profile.d/term.sh

          # Configure networking
          sudo tee /mnt/ubuntu/etc/netplan/01-dhcp.yaml > /dev/null <<'NETPLAN'
          network:
            version: 2
            ethernets:
              eth0:
                dhcp4: true
          NETPLAN

          sudo umount /mnt/ubuntu

          # Clean up
          rm -f /tmp/ubuntu-rootfs.tar.xz

          ls -lh images/ubuntu-24.04-minimal.ext4

      - name: Build Node.js function runtime
        run: |
          cd $GITHUB_WORKSPACE
          # Script auto-converts relative OUTPUT_IMAGE to absolute path
          sudo OUTPUT_IMAGE="images/node-runtime.ext4" bash scripts/runtime-images/build-node-runtime.sh
          ls -lh images/node-runtime.ext4

      - name: Build Python function runtime
        run: |
          cd $GITHUB_WORKSPACE
          # Script auto-converts relative OUTPUT_IMAGE to absolute path
          sudo OUTPUT_IMAGE="images/python-runtime.ext4" bash scripts/runtime-images/build-python-runtime.sh
          ls -lh images/python-runtime.ext4

      - name: Build Bun function runtime
        run: |
          cd $GITHUB_WORKSPACE
          # Script auto-converts relative OUTPUT_IMAGE to absolute path
          sudo OUTPUT_IMAGE="images/bun-runtime.ext4" bash scripts/runtime-images/build-bun-runtime.sh
          ls -lh images/bun-runtime.ext4

      - name: Build container runtime (Alpine + Docker)
        run: |
          # Build container runtime for Docker-in-VM feature (matches scripts/build-container-runtime-v2.sh)
          ALPINE_VERSION=3.18
          curl -fsSL -o /tmp/alpine-container.tar.gz \
            https://dl-cdn.alpinelinux.org/alpine/v${ALPINE_VERSION}/releases/x86_64/alpine-minirootfs-${ALPINE_VERSION}.0-x86_64.tar.gz

          # Create ext4 image (2.2GB for Docker runtime)
          dd if=/dev/zero of=images/container-runtime.ext4 bs=1M count=2200
          mkfs.ext4 -F images/container-runtime.ext4

          sudo mkdir -p /mnt/container
          sudo mount -o loop images/container-runtime.ext4 /mnt/container
          sudo tar -xzf /tmp/alpine-container.tar.gz -C /mnt/container

          # Configure DNS
          sudo cp /etc/resolv.conf /mnt/container/etc/resolv.conf

          # Install Docker and dependencies
          sudo chroot /mnt/container sh -c '
            apk update
            apk add --no-cache \
              docker \
              docker-openrc \
              openrc \
              util-linux \
              coreutils \
              bash \
              curl \
              wget \
              ca-certificates \
              e2fsprogs \
              iptables \
              ip6tables \
              iproute2 \
              bridge-utils \
              openssh \
              shadow

            # Configure OpenRC boot services
            rc-update add devfs boot
            rc-update add procfs boot
            rc-update add sysfs boot
            rc-update add cgroups boot
            rc-update add networking boot
            rc-update add docker default

            # Set root password
            echo "root:root" | chpasswd
          '

          # Create proper /etc/inittab for BusyBox init with OpenRC (matching working dev image)
          printf '%s\n' \
            '# /etc/inittab' \
            '' \
            '::sysinit:/sbin/openrc sysinit' \
            '::sysinit:/sbin/openrc boot' \
            '::wait:/sbin/openrc default' \
            '' \
            '# Set up a couple of gettys' \
            'tty1::respawn:/sbin/getty 38400 tty1' \
            'tty2::respawn:/sbin/getty 38400 tty2' \
            'tty3::respawn:/sbin/getty 38400 tty3' \
            'tty4::respawn:/sbin/getty 38400 tty4' \
            'tty5::respawn:/sbin/getty 38400 tty5' \
            'tty6::respawn:/sbin/getty 38400 tty6' \
            '' \
            '# Put a getty on the serial port' \
            '#ttyS0::respawn:/sbin/getty -L ttyS0 115200 vt100' \
            '' \
            '# Stuff to do for the 3-finger salute' \
            '::ctrlaltdel:/sbin/reboot' \
            '' \
            '# Stuff to do before rebooting' \
            '::shutdown:/sbin/openrc shutdown' \
            | sudo tee /mnt/container/etc/inittab > /dev/null

          # Configure Docker daemon for OpenRC
          sudo mkdir -p /mnt/container/etc/docker /mnt/container/etc/conf.d

          # OpenRC configuration for Docker
          printf '%s\n' \
            '# Docker daemon options for OpenRC' \
            'DOCKER_OPTS="-H unix:///var/run/docker.sock -H tcp://0.0.0.0:2375"' \
            | sudo tee /mnt/container/etc/conf.d/docker > /dev/null

          # Docker daemon JSON config - NO hosts here (they are in DOCKER_OPTS)
          printf '%s\n' \
            '{' \
            '    "storage-driver": "overlay2",' \
            '    "log-driver": "json-file",' \
            '    "log-opts": {' \
            '        "max-size": "10m",' \
            '        "max-file": "3"' \
            '    }' \
            '}' \
            | sudo tee /mnt/container/etc/docker/daemon.json > /dev/null

          # Create docker-force init script that reliably starts Docker with TCP
          printf '%s\n' \
            '#!/sbin/openrc-run' \
            '' \
            'description="Force start Docker daemon with TCP support"' \
            '' \
            'depend() {' \
            '    need net' \
            '    after firewall' \
            '}' \
            '' \
            'start() {' \
            '    ebegin "Starting Docker daemon with TCP support"' \
            '    mkdir -p /var/run /var/lib/docker' \
            '    /usr/bin/dockerd \' \
            '        --host=unix:///var/run/docker.sock \' \
            '        --host=tcp://0.0.0.0:2375 \' \
            '        --storage-driver=overlay2 \' \
            '        --log-driver=json-file \' \
            '        --log-opt max-size=10m \' \
            '        --log-opt max-file=3 \' \
            '        > /var/log/docker.log 2>&1 &' \
            '    DOCKER_PID=$!' \
            '    echo $DOCKER_PID > /var/run/docker.pid' \
            '    for i in $(seq 1 30); do' \
            '        if /usr/bin/docker info >/dev/null 2>&1; then' \
            '            eend 0 "Docker daemon started successfully"' \
            '            return 0' \
            '        fi' \
            '        sleep 1' \
            '    done' \
            '    eend 1 "Docker daemon failed to start"' \
            '    return 1' \
            '}' \
            '' \
            'stop() {' \
            '    ebegin "Stopping Docker daemon"' \
            '    if [ -f /var/run/docker.pid ]; then' \
            '        kill $(cat /var/run/docker.pid)' \
            '        rm -f /var/run/docker.pid' \
            '    fi' \
            '    eend 0' \
            '}' \
            | sudo tee /mnt/container/etc/init.d/docker-force > /dev/null
          sudo chmod +x /mnt/container/etc/init.d/docker-force

          # Use docker-force instead of regular docker, and add local service
          sudo chroot /mnt/container sh -c '
            rc-update del docker default 2>/dev/null || true
            rc-update add docker-force default
            rc-update add local default
          '

          # Create network config
          printf '%s\n' \
            'auto lo' \
            'iface lo inet loopback' \
            '' \
            'auto eth0' \
            'iface eth0 inet dhcp' \
            | sudo tee /mnt/container/etc/network/interfaces > /dev/null

          # Set TERM for serial console
          sudo mkdir -p /mnt/container/etc/profile.d
          echo 'export TERM=vt100' | sudo tee /mnt/container/etc/profile.d/term.sh
          sudo chmod +x /mnt/container/etc/profile.d/term.sh

          echo "container-runtime" | sudo tee /mnt/container/etc/hostname

          sudo umount /mnt/container
          ls -lh images/container-runtime.ext4

      - name: Compress large images
        run: |
          # Compress larger images (>100MB) to reduce upload size
          cd images
          for img in ubuntu-24.04-minimal.ext4 node-runtime.ext4 python-runtime.ext4 bun-runtime.ext4 container-runtime.ext4; do
            if [ -f "$img" ]; then
              echo "Compressing $img..."
              gzip -9 -k "$img"
              ls -lh "${img}.gz"
            fi
          done
          echo "All images:"
          ls -lh

      - name: Upload images as artifacts
        uses: actions/upload-artifact@v4
        with:
          name: base-images
          path: |
            images/vmlinux-5.10.fc.bin
            images/alpine-3.18-minimal.ext4
            images/busybox-1.35.ext4
            images/ubuntu-24.04-minimal.ext4.gz
            images/node-runtime.ext4.gz
            images/python-runtime.ext4.gz
            images/bun-runtime.ext4.gz
            images/container-runtime.ext4.gz
          retention-days: 1

  build-ui:
    name: Build UI
    needs: ci-gate
    runs-on: ubuntu-24.04

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install pnpm
        run: npm install -g pnpm

      - name: Cache pnpm
        uses: actions/cache@v4
        with:
          path: |
            ~/.pnpm-store
            apps/ui/node_modules
          key: ${{ runner.os }}-pnpm-${{ hashFiles('apps/ui/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-

      - name: Install UI dependencies
        working-directory: apps/ui
        run: pnpm install --frozen-lockfile

      - name: Build UI
        working-directory: apps/ui
        run: pnpm build

      - name: Package UI
        run: |
          cd apps/ui
          tar czf ../../nqrust-ui.tar.gz \
            .next/ \
            public/ \
            package.json \
            next.config.mjs \
            pnpm-lock.yaml

      - name: Upload UI as artifact
        uses: actions/upload-artifact@v4
        with:
          name: ui-build
          path: nqrust-ui.tar.gz
          retention-days: 1

  create-release:
    name: Create GitHub Release
    needs: [build-binaries, build-ui, build-images]
    runs-on: ubuntu-24.04
    permissions:
      contents: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/

      - name: Decompress large images (except container-runtime which exceeds 2GB limit)
        run: |
          cd artifacts/base-images
          for gz in *.gz; do
            if [ -f "$gz" ]; then
              # Skip container-runtime - it's >2GB uncompressed, keep it gzipped
              if [ "$gz" = "container-runtime.ext4.gz" ]; then
                echo "Keeping $gz compressed (>2GB uncompressed)"
                continue
              fi
              gunzip -k "$gz"
            fi
          done
          ls -lh

      - name: Package installer scripts
        run: |
          tar czf nqrust-installer.tar.gz \
            scripts/install/install.sh \
            scripts/install/uninstall.sh \
            scripts/install/README.md \
            scripts/install/lib/ \
            scripts/install/systemd/ \
            scripts/install/sudoers.d/

      - name: Organize release files
        run: |
          mkdir -p release/
          find artifacts/ -type f -name "nqrust-*" -exec cp {} release/ \;
          find artifacts/ -type f -name "nqr-installer-*" -exec cp {} release/ \;
          cp nqrust-installer.tar.gz release/
          # Copy base images (uncompressed .ext4 and kernel)
          cp artifacts/base-images/vmlinux-5.10.fc.bin release/
          cp artifacts/base-images/alpine-3.18-minimal.ext4 release/
          cp artifacts/base-images/busybox-1.35.ext4 release/
          cp artifacts/base-images/ubuntu-24.04-minimal.ext4 release/
          cp artifacts/base-images/node-runtime.ext4 release/
          cp artifacts/base-images/python-runtime.ext4 release/
          cp artifacts/base-images/bun-runtime.ext4 release/
          # Container runtime stays compressed (>2GB uncompressed exceeds GitHub limit)
          cp artifacts/base-images/container-runtime.ext4.gz release/
          ls -lh release/

      - name: Generate checksums
        working-directory: release
        run: |
          sha256sum nqrust-manager-* > checksums.txt
          sha256sum nqrust-agent-* >> checksums.txt
          sha256sum nqrust-guest-agent-* >> checksums.txt
          sha256sum nqr-installer-* >> checksums.txt
          sha256sum nqrust-ui.tar.gz >> checksums.txt
          sha256sum nqrust-installer.tar.gz >> checksums.txt
          sha256sum vmlinux-*.bin >> checksums.txt
          sha256sum *.ext4 >> checksums.txt
          sha256sum *.ext4.gz >> checksums.txt 2>/dev/null || true
          cat checksums.txt

      - name: Get version
        id: version
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            VERSION="${{ github.event.inputs.version }}"
          else
            VERSION="${GITHUB_REF#refs/tags/}"
          fi
          echo "version=$VERSION" >> $GITHUB_OUTPUT

          # Check if this is a pre-release (v0.x.x or contains -alpha, -beta, -rc)
          if [[ "$VERSION" =~ ^v0\. ]] || [[ "$VERSION" =~ -(alpha|beta|rc) ]]; then
            echo "prerelease=true" >> $GITHUB_OUTPUT
          else
            echo "prerelease=false" >> $GITHUB_OUTPUT
          fi

      - name: Create release manifest
        working-directory: release
        run: |
          cat > release-manifest.json <<EOF
          {
            "version": "${{ steps.version.outputs.version }}",
            "released_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "min_compatible_version": "v0.1.0",
            "changelog": "See CHANGELOG.md for details",
            "components": {
              "manager": {
                "version": "${{ steps.version.outputs.version }}",
                "url": "https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/nqrust-manager-x86_64-unknown-linux-gnu",
                "checksum": "$(sha256sum nqrust-manager-x86_64-unknown-linux-gnu | cut -d' ' -f1)",
                "size": $(stat -f%z nqrust-manager-x86_64-unknown-linux-gnu 2>/dev/null || stat -c%s nqrust-manager-x86_64-unknown-linux-gnu)
              },
              "agent": {
                "version": "${{ steps.version.outputs.version }}",
                "url": "https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/nqrust-agent-x86_64-unknown-linux-gnu",
                "checksum": "$(sha256sum nqrust-agent-x86_64-unknown-linux-gnu | cut -d' ' -f1)",
                "size": $(stat -f%z nqrust-agent-x86_64-unknown-linux-gnu 2>/dev/null || stat -c%s nqrust-agent-x86_64-unknown-linux-gnu)
              },
              "guest-agent": {
                "version": "${{ steps.version.outputs.version }}",
                "url": "https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/nqrust-guest-agent-x86_64-linux-musl",
                "checksum": "$(sha256sum nqrust-guest-agent-x86_64-linux-musl | cut -d' ' -f1)",
                "size": $(stat -f%z nqrust-guest-agent-x86_64-linux-musl 2>/dev/null || stat -c%s nqrust-guest-agent-x86_64-linux-musl)
              },
              "ui": {
                "version": "${{ steps.version.outputs.version }}",
                "url": "https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/nqrust-ui.tar.gz",
                "checksum": "$(sha256sum nqrust-ui.tar.gz | cut -d' ' -f1)",
                "size": $(stat -f%z nqrust-ui.tar.gz 2>/dev/null || stat -c%s nqrust-ui.tar.gz)
              },
              "installer": {
                "version": "${{ steps.version.outputs.version }}",
                "url": "https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/nqrust-installer.tar.gz",
                "checksum": "$(sha256sum nqrust-installer.tar.gz | cut -d' ' -f1)",
                "size": $(stat -f%z nqrust-installer.tar.gz 2>/dev/null || stat -c%s nqrust-installer.tar.gz)
              }
            },
            "migrations": {
              "from": "v0.1.0",
              "requires_downtime": false,
              "breaking_changes": false
            }
          }
          EOF

          cat release-manifest.json
          jq '.' release-manifest.json  # Validate JSON

      - name: Generate release notes
        id: release_notes
        run: |
          cat > release_notes.md <<'EOF'
          ## NQRust-MicroVM ${{ steps.version.outputs.version }}

          ### Installation

          **Quick Install (Ubuntu 22.04+):**
          ```bash
          curl -fsSL https://raw.githubusercontent.com/${{ github.repository }}/main/scripts/install/install.sh | bash
          ```

          **Manual Install:**
          ```bash
          # Download installer
          curl -LO https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/nqr-installer-x86_64-linux-musl
          chmod +x nqr-installer-x86_64-linux-musl

          # Run installer (interactive TUI)
          sudo ./nqr-installer-x86_64-linux-musl install

          # Or with options
          sudo ./nqr-installer-x86_64-linux-musl install --mode production --yes
          ```

          ### Pre-built Binaries

          Download and install manually:
          - **Installer (Rust TUI)**: [nqr-installer-x86_64-linux-musl](https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/nqr-installer-x86_64-linux-musl) (Recommended)
          - Manager: [nqrust-manager-x86_64-unknown-linux-gnu](https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/nqrust-manager-x86_64-unknown-linux-gnu)
          - Agent: [nqrust-agent-x86_64-unknown-linux-gnu](https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/nqrust-agent-x86_64-unknown-linux-gnu)
          - Guest Agent: [nqrust-guest-agent-x86_64-linux-musl](https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/nqrust-guest-agent-x86_64-linux-musl)
          - UI: [nqrust-ui.tar.gz](https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/nqrust-ui.tar.gz)
          - Legacy Installer Scripts: [nqrust-installer.tar.gz](https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/nqrust-installer.tar.gz)

          ### Base Images (for VMs and Functions)

          The installer downloads these automatically, or download manually:
          - **Kernel**: [vmlinux-5.10.fc.bin](https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/vmlinux-5.10.fc.bin) - Firecracker kernel 5.10
          - **Alpine**: [alpine-3.18-minimal.ext4](https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/alpine-3.18-minimal.ext4) - Alpine Linux 3.18 minimal
          - **BusyBox**: [busybox-1.35.ext4](https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/busybox-1.35.ext4) - BusyBox 1.35
          - **Ubuntu**: [ubuntu-24.04-minimal.ext4](https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/ubuntu-24.04-minimal.ext4) - Ubuntu 24.04 minimal
          - **Node.js Runtime**: [node-runtime.ext4](https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/node-runtime.ext4) - For serverless functions
          - **Python Runtime**: [python-runtime.ext4](https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/python-runtime.ext4) - For serverless functions
          - **Bun Runtime**: [bun-runtime.ext4](https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/bun-runtime.ext4) - For serverless functions (TypeScript/JS)
          - **Container Runtime**: [container-runtime.ext4.gz](https://github.com/${{ github.repository }}/releases/download/${{ steps.version.outputs.version }}/container-runtime.ext4.gz) - Docker-in-VM (~2.2GB, gzipped)

          ### Checksums
          ```
          $(cat release/checksums.txt)
          ```

          ### Requirements
          - Ubuntu 22.04+ or Debian 11+ or RHEL 8+
          - x86_64 CPU with KVM support
          - 2GB+ RAM
          - 20GB+ disk space

          ### What's New
          - See [CHANGELOG.md](https://github.com/${{ github.repository }}/blob/main/CHANGELOG.md) for details

          ### Documentation
          - [Installation Guide](https://github.com/${{ github.repository }}/blob/main/README.md)
          - [Quick Start](https://github.com/${{ github.repository }}/blob/main/RUN.md)
          - [Features](https://github.com/${{ github.repository }}/blob/main/FEATURES.md)
          EOF

          echo "notes_file=release_notes.md" >> $GITHUB_OUTPUT

      - name: Create GitHub Release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: ${{ steps.version.outputs.version }}
          name: Release ${{ steps.version.outputs.version }}
          body_path: ${{ steps.release_notes.outputs.notes_file }}
          draft: false
          prerelease: ${{ steps.version.outputs.prerelease }}
          files: |
            release/nqrust-manager-x86_64-unknown-linux-gnu
            release/nqrust-agent-x86_64-unknown-linux-gnu
            release/nqrust-guest-agent-x86_64-linux-musl
            release/nqr-installer-x86_64-linux-musl
            release/nqrust-ui.tar.gz
            release/nqrust-installer.tar.gz
            release/checksums.txt
            release/release-manifest.json
            release/vmlinux-5.10.fc.bin
            release/alpine-3.18-minimal.ext4
            release/busybox-1.35.ext4
            release/ubuntu-24.04-minimal.ext4
            release/node-runtime.ext4
            release/python-runtime.ext4
            release/bun-runtime.ext4
            release/container-runtime.ext4.gz
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload release manifest as latest
        uses: softprops/action-gh-release@v1
        with:
          tag_name: latest
          name: Latest Release
          body: "Latest release manifest for auto-updater"
          draft: false
          prerelease: false
          files: release/release-manifest.json
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # TODO: Re-enable installer tests in v0.1.1 after fixing disk space and permission issues
  # test-installer:
  #   name: Test Installer
  #   needs: create-release
  #   runs-on: ubuntu-24.04
  #   strategy:
  #     matrix:
  #       mode: [production, dev, manager, agent]
  #
  #   steps:
  #     - name: Checkout code
  #       uses: actions/checkout@v4
  #
  #     - name: Test installer (${{ matrix.mode }} mode)
  #       run: |
  #         # Test in non-interactive mode (installer will use sudo internally)
  #         # Use /tmp for logs to avoid permission issues in CI
  #         LOG_DIR=/tmp/nqrust-install bash scripts/install/install.sh \
  #           --mode ${{ matrix.mode }} \
  #           --non-interactive \
  #           --network-mode nat
  #
  #     - name: Verify services
  #       if: matrix.mode != 'agent'
  #       run: |
  #         systemctl is-active nqrust-manager
  #         curl -f http://localhost:18080/health
  #
  #     - name: Verify agent
  #       if: matrix.mode != 'manager'
  #       run: |
  #         systemctl is-active nqrust-agent
  #         curl -f http://localhost:9090/health
  #
  #     - name: Show logs on failure
  #       if: failure()
  #       run: |
  #         journalctl -u nqrust-manager -n 100 --no-pager || true
  #         journalctl -u nqrust-agent -n 100 --no-pager || true
  #
  #     - name: Test uninstaller
  #       run: |
  #         bash scripts/install/uninstall.sh \
  #           --force \
  #           --remove-all
